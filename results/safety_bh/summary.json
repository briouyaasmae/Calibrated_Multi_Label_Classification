{
  "scores": {
    "micro_f1": 0.8245224344735673,
    "macro_f1": 0.790494308833866,
    "samples_f1": 0.7740104327852673,
    "jaccard_macro": 0.6640524979125288,
    "jaccard_samples": 0.6866879533270261,
    "subset_accuracy": 0.2693156732891832,
    "hamming_loss": 0.1634933774834437,
    "micro_acc": 0.8365066225165563,
    "throughput_tokens_per_sec": 63538.60189558762
  },
  "args": {
    "train": "/kaggle/working/Dataset_ready/train_ready.json",
    "val": "/kaggle/working/Dataset_ready/val_ready.json",
    "test": "/kaggle/working/Dataset_ready/test_ready.json",
    "output_dir": "runs/depressionemo/jbi_eval_plus/safety_bh",
    "model_name": "roberta-base",
    "max_length": 256,
    "truncation_mode": "headtail",
    "head_ratio": 0.6,
    "batch_size": 16,
    "eval_batch_size": 32,
    "learning_rate": 2e-05,
    "weight_decay": 0.01,
    "warmup_ratio": 0.1,
    "epochs": 6,
    "grad_accum": 1,
    "seed": 42,
    "gradient_checkpointing": false,
    "max_grad_norm": 1.0,
    "attn_dim": 256,
    "graph_lambda": 0.12,
    "loss": "asl",
    "asl_gamma_pos": 1.0,
    "asl_gamma_neg": 2.0,
    "asl_clip": 0.05,
    "f1_finetune_epochs": 1,
    "f1_finetune_beta": 1.0,
    "f1_finetune_lr_scale": 0.5,
    "f1_finetune_freeze_backbone": true,
    "threshold_mode": "auto",
    "th_metric": "f1",
    "th_fbeta": 1.0,
    "th_min_pos_support": 6,
    "th_shrink": 0.9,
    "th_clip_low": 0.3,
    "th_clip_high": 0.98,
    "th_min_improve": 0.005,
    "th_precision_floor": 0.25,
    "use_rare_sampler": true,
    "sampler_power": 0.6,
    "rare_label_threshold": 0.1,
    "save_pr_curves": false,
    "save_calibration_bins": false,
    "safety_labels": "suicide_intent",
    "target_precision": 0.85,
    "fdr_method": "bh",
    "fdr_alpha": 0.15,
    "primary_label": "suicide_intent",
    "bootstrap_B": 1000,
    "save_val_arrays": true
  }
}